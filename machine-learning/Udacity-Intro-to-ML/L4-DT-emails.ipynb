{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Decision Tree to categorize emails\n",
    "\n",
    "## Decision Tree Mini Project\n",
    "\n",
    "In this project, we will again try to classify emails, this time using a decision tree.   The starter code is in decision_tree/dt_author_id.py.\n",
    "\n",
    "### Part 1: Get the Decision Tree Running\n",
    "Get the decision tree up and running as a classifier, setting min_samples_split=40.  It will probably take a while to train.  What’s the accuracy?\n",
    "\n",
    "### Part 2: Speed It Up\n",
    "You found in the SVM mini-project that the parameter tune can significantly speed up the training time of a machine learning algorithm.  A general rule is that the parameters can tune the complexity of the algorithm, with more complex algorithms generally running more slowly.  \n",
    "\n",
    "Another way to control the complexity of an algorithm is via the number of features that you use in training/testing.  The more features the algorithm has available, the more potential there is for a complex fit.  We will explore this in detail in the “Feature Selection” lesson, but you’ll get a sneak preview now.\n",
    "\n",
    "- find the number of features in your data.  The data is organized into a numpy array where the number of rows is the number of data points and the number of columns is the number of features; so to extract this number, use a line of code like len(features_train[0])\n",
    "- go into tools/email_preprocess.py, and find the line of code that looks like this:     selector = SelectPercentile(f_classif, percentile=1)  Change percentile from 10 to 1.\n",
    "- What’s the number of features now?\n",
    "- What do you think SelectPercentile is doing?  Would a large value for percentile lead to a more complex or less complex decision tree, all other things being equal?\n",
    "- Note the difference in training time depending on the number of features.  \n",
    "- What’s the accuracy when percentile = 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from email_preprocess import preprocess_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore from cache\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess_emails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cache_sklearn_model import retrieve_cached_model, save_cached_model\n",
    "\n",
    "def optimize_dt(amount_of_training_data = 1,\n",
    "                features = None,\n",
    "                labels = None,\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if features is not None and labels is not None:\n",
    "        pass\n",
    "    elif amount_of_training_data == 1:\n",
    "        features = features_train\n",
    "        labels = labels_train\n",
    "    else:\n",
    "        features,_,labels,_ = train_test_split(\n",
    "            features_train,\n",
    "            labels_train,\n",
    "            train_size=amount_of_training_data,\n",
    "            random_state=91,\n",
    "        )\n",
    "\n",
    "    print(\"training on\", len(features), \"out of\", len(features_train),\n",
    "          \"(\", len(features)/len(features_train)*100 ,\"%)\"\n",
    "         )\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state = 45, **kwargs)\n",
    "    \n",
    "    data_desc = f'preprocess_emails_{amount_of_training_data*100}'\n",
    "    [is_restored, clf, meta] = retrieve_cached_model(clf, data_desc)\n",
    "    \n",
    "    fit_delta = meta.get(\"fit_time_sec\")\n",
    "    if not is_restored:\n",
    "        t = time()\n",
    "        clf.fit(features, labels)\n",
    "        fit_delta = round(time()-t, 3)\n",
    "        save_cached_model(clf, data_desc, {\"fit_time_sec\": fit_delta})\n",
    "    print(\"clf fit time:\", fit_delta, \"s\")\n",
    "    \n",
    "    # output predictions\n",
    "    t = time()\n",
    "    labels_pred = clf.predict(features_test)\n",
    "    pred_delta = round(time()-t, 3)\n",
    "    print(\"clf predict time:\", pred_delta, \"s\")\n",
    "    \n",
    "    accuracy = accuracy_score(labels_pred, labels_test)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    \n",
    "    print(f'| {amount_of_training_data} | {kwargs} | {fit_delta}s | {pred_delta}s | {accuracy} |')\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How long do DTs take to compute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 1582 out of 15820 ( 10.0 %)\n",
      "clf fit time: 0.94 s\n",
      "clf predict time: 0.016 s\n",
      "accuracy: 0.8799772468714449\n",
      "| 0.1 | {} | 0.94s | 0.016s | 0.8799772468714449 |\n"
     ]
    }
   ],
   "source": [
    "_ = optimize_dt(amount_of_training_data = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 3164 out of 15820 ( 20.0 %)\n",
      "clf fit time: 4.844 s\n",
      "clf predict time: 0.011 s\n",
      "accuracy: 0.934584755403868\n",
      "| 0.2 | {} | 4.844s | 0.011s | 0.934584755403868 |\n"
     ]
    }
   ],
   "source": [
    "_ = optimize_dt(amount_of_training_data = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 6328 out of 15820 ( 40.0 %)\n",
      "clf fit time: 19.802 s\n",
      "clf predict time: 0.01 s\n",
      "accuracy: 0.9556313993174061\n",
      "| 0.4 | {} | 19.802s | 0.01s | 0.9556313993174061 |\n"
     ]
    }
   ],
   "source": [
    "_ = optimize_dt(amount_of_training_data = 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 12656 out of 15820 ( 80.0 %)\n",
      "clf fit time: 57.472 s\n",
      "clf predict time: 0.011 s\n",
      "accuracy: 0.9732650739476678\n",
      "| 0.8 | {} | 57.472s | 0.011s | 0.9732650739476678 |\n"
     ]
    }
   ],
   "source": [
    "_ = optimize_dt(amount_of_training_data = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 15820 out of 15820 ( 100.0 %)\n",
      "clf fit time: 80.054 s\n",
      "clf predict time: 0.013 s\n",
      "accuracy: 0.9908987485779295\n",
      "| 1 | {} | 80.054s | 0.013s | 0.9908987485779295 |\n"
     ]
    }
   ],
   "source": [
    "_ = optimize_dt(amount_of_training_data = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do different params perform on this dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
